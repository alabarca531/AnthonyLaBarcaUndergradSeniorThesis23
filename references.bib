@inproceedings{fukushima1979,
    author = {Fukushima, Kunihiko},
    title = {Self-Organization of a Neural Network Which Gives Position-Invariant Response},
    year = {1979},
    isbn = {0934613478},
    publisher = {Morgan Kaufmann Publishers Inc.},
    address = {San Francisco, CA, USA},
    abstract = {In this paper, I propose a new algorithm for self-organizing a multilayered neural network which has an ability to recognize patterns based on the geometrical similarity of their shapes. This network, whose nickname is "neo-cognitron", has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consists of a photoreceptor layer followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of "S-cells", which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of "C-cells" similar to complex cells or higher order hypercomplex cells. The input synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We don't need any "teacher" during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer. The network has been simulated on a digital computer. After completion of self-organization, the stimulus patterns has become to elicit their own response from the last C-cell layer. That is, the response of the last C-cell layer changes without fail, if a stimulus patterns of a different category is presented to the input layer. The response of that layer, however, is not affected by the pattern's position at all. Neither is it affected by a certain amount of changes of the pattern's shape or size.},
    booktitle = {Proceedings of the 6th International Joint Conference on Artificial Intelligence - Volume 1},
    pages = {291–293},
    numpages = {3},
    location = {Tokyo, Japan},
    series = {IJCAI'79},
    doi = {10.5555/1624861.1624928}
}
@article{cybenko1989,
	abstract = {In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.},
	author = {Cybenko, G. },
	date = {1989/12/01},
	date-added = {2023-04-02 14:28:57 -0400},
	date-modified = {2023-04-02 14:28:57 -0400},
	doi = {10.1007/BF02551274},
	id = {Cybenko1989},
	isbn = {1435-568X},
	journal = {Mathematics of Control, Signals and Systems},
	number = {4},
	pages = {303--314},
	title = {Approximation by superpositions of a sigmoidal function},
	url = {https://doi.org/10.1007/BF02551274},
	volume = {2},
	year = {1989},
	bdsk-url-1 = {https://doi.org/10.1007/BF02551274}
}
@inproceedings{krizhevsky2012,
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
	publisher = {Curran Associates, Inc.},
	title = {ImageNet Classification with Deep Convolutional Neural Networks},
	url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
	volume = {25},
	year = {2012},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf}
}
@INPROCEEDINGS{lecun2004,
  author={LeCun, Y. and Fu Jie Huang and Bottou, L.},
  booktitle={Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.}, 
  title={Learning methods for generic object recognition with invariance to pose and lighting}, 
  year={2004},
  volume={2},
  number={},
  pages={II-104 Vol.2},
  doi={10.1109/CVPR.2004.1315150}}

  
@article{parks2018,
	abstract = {{We have designed, developed, and applied a convolutional neural network (CNN) architecture using multi-task learning to search for and characterize strong H i Lyα absorption in quasar spectra. Without any explicit modelling of the quasar continuum or application of the predicted line profile for Lyα from quantum mechanics, our algorithm predicts the presence of strong H i absorption and estimates the corresponding redshift zabs and H i column density \\$N\_\\{\\rm H\\,\\small \\{I\\}\\}\\$, with emphasis on damped Lyα systems (DLAs, absorbers with \\$N\_\\{\\rm H\\,\\small \\{I\\}\\}\\ge 2 \\times 10^\\{20\\} \\, \\{\\rm cm^\\{-2\\}\\}\\$). We tuned the CNN model using a custom training set of DLAs injected into DLA-free quasar spectra from the Sloan Digital Sky Survey (SDSS), data release 5 (DR5). Testing on a held-back validation set demonstrates a high incidence of DLAs recovered by the algorithm (97.4 per cent as DLAs and 99 per cent as an H i absorber with \\$N\_\\{\\rm H\\,\\small \\{I\\}\\}\\&gt; 10^\\{19.5\\} \\, \\{\\rm cm^\\{-2\\}\\}\\$) and excellent estimates for zabs and \\$N\_\\{\\rm H\\,\\small \\{I\\}\\}\\$. Similar results are obtained against a human-generated survey of the SDSS DR5 data set. The algorithm yields a low incidence of false positives and negatives but is challenged by overlapping DLAs and/or very high \\$N\_\\{\\rm H\\,\\small \\{I\\}\\}\\$ systems. We have applied this CNN model to the quasar spectra of SDSS DR7 and the Baryon Oscillation Spectroscopic Survey (data release 12) and provide catalogues of 4913 and 50 969 DLAs, respectively (including 1659 and 9230 high-confidence DLAs that were previously unpublished). This work validates the application of deep learning techniques to astronomical spectra for both classification and quantitative measurements.}},
	author = {Parks, David and Prochaska, J Xavier and Dong, Shawfeng and Cai, Zheng},
	doi = {10.1093/mnras/sty196},
	eprint = {https://academic.oup.com/mnras/article-pdf/476/1/1151/24261051/sty196.pdf},
	issn = {0035-8711},
	journal = {Monthly Notices of the Royal Astronomical Society},
	month = {01},
	number = {1},
	pages = {1151-1168},
	title = {{Deep learning of quasar spectra to discover and characterize damped Lyα systems}},
	url = {https://doi.org/10.1093/mnras/sty196},
	volume = {476},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1093/mnras/sty196}}

@inproceedings{vaswani2017,
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Attention is All you Need},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
	volume = {30},
	year = {2017},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}}

@article{dosovitskiy2020,
  author    = {Alexey Dosovitskiy and
               Lucas Beyer and
               Alexander Kolesnikov and
               Dirk Weissenborn and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Mostafa Dehghani and
               Matthias Minderer and
               Georg Heigold and
               Sylvain Gelly and
               Jakob Uszkoreit and
               Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition
               at Scale},
  journal   = {CoRR},
  volume    = {abs/2010.11929},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.11929},
  eprinttype = {arXiv},
  eprint    = {2010.11929},
  timestamp = {Fri, 20 Nov 2020 14:04:05 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-11929.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
