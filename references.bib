@inproceedings{fukushima1979,
  abstract  = {In this paper, I propose a new algorithm for self-organizing a multilayered neural network which has an ability to recognize patterns based on the geometrical similarity of their shapes. This network, whose nickname is "neo-cognitron", has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consists of a photoreceptor layer followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of "S-cells", which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of "C-cells" similar to complex cells or higher order hypercomplex cells. The input synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We don't need any "teacher" during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer. The network has been simulated on a digital computer. After completion of self-organization, the stimulus patterns has become to elicit their own response from the last C-cell layer. That is, the response of the last C-cell layer changes without fail, if a stimulus patterns of a different category is presented to the input layer. The response of that layer, however, is not affected by the pattern's position at all. Neither is it affected by a certain amount of changes of the pattern's shape or size.},
  author    = {Fukushima, Kunihiko},
  location  = {Tokyo, Japan},
  publisher = {Morgan Kaufmann Publishers Inc.},
  booktitle = {Proceedings of the 6th International Joint Conference on Artificial Intelligence - Volume 1},
  date      = {1979},
  doi       = {10.5555/1624861.1624928},
  isbn      = {0934613478},
  pages     = {291--293},
  series    = {IJCAI'79},
  title     = {Self-Organization of a Neural Network Which Gives Position-Invariant Response},
}

@article{cybenko1989,
  abstract     = {In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.},
  author       = {Cybenko, G.},
  url          = {https://doi.org/10.1007/BF02551274},
  date         = {1989-12-01},
  doi          = {10.1007/BF02551274},
  isbn         = {1435-568X},
  journaltitle = {Mathematics of Control, Signals and Systems},
  number       = {4},
  pages        = {303--314},
  title        = {Approximation by superpositions of a sigmoidal function},
  volume       = {2},
}

@inproceedings{krizhevsky2012,
  author    = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  editor    = {Pereira, F. and Burges, C.J. and Bottou, L. and Weinberger, K.Q.},
  publisher = {Curran Associates, Inc.},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
  booktitle = {Advances in Neural Information Processing Systems},
  date      = {2012},
  title     = {ImageNet Classification with Deep Convolutional Neural Networks},
  volume    = {25},
}

@inproceedings{lecun2004,
  author    = {LeCun, Y. and Huang, F. and Bottou, L.},
  booktitle = {Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.},
  date      = {2004},
  doi       = {10.1109/CVPR.2004.1315150},
  pages     = {II--104 Vol.2},
  title     = {Learning methods for generic object recognition with invariance to pose and lighting},
  volume    = {2},
}

@article{parks2018,
  abstract     = {{We have designed, developed, and applied a convolutional neural network (CNN) architecture using multi-task learning to search for and characterize strong H i Ly$\alpha$ absorption in quasar spectra. Without any explicit modelling of the quasar continuum or application of the predicted line profile for Ly$\alpha$ from quantum mechanics, our algorithm predicts the presence of strong H i absorption and estimates the corresponding redshift zabs and H i column density \\$N\_\\{\\rm H\\,\\small \\{I\\}\\}\\$, with emphasis on damped Ly$\alpha$ systems (DLAs, absorbers with \\$N\_\\{\\rm H\\,\\small \\{I\\}\\}\\ge 2 \\times 10^\\{20\\} \\, \\{\\rm cm^\\{-2\\}\\}\\$). We tuned the CNN model using a custom training set of DLAs injected into DLA-free quasar spectra from the Sloan Digital Sky Survey (SDSS), data release 5 (DR5). Testing on a held-back validation set demonstrates a high incidence of DLAs recovered by the algorithm (97.4 per cent as DLAs and 99 per cent as an H i absorber with \\$N\_\\{\\rm H\\,\\small \\{I\\}\\}\\&gt; 10^\\{19.5\\} \\, \\{\\rm cm^\\{-2\\}\\}\\$) and excellent estimates for zabs and \\$N\_\\{\\rm H\\,\\small \\{I\\}\\}\\$. Similar results are obtained against a human-generated survey of the SDSS DR5 data set. The algorithm yields a low incidence of false positives and negatives but is challenged by overlapping DLAs and/or very high \\$N\_\\{\\rm H\\,\\small \\{I\\}\\}\\$ systems. We have applied this CNN model to the quasar spectra of SDSS DR7 and the Baryon Oscillation Spectroscopic Survey (data release 12) and provide catalogues of 4913 and 50 969 DLAs, respectively (including 1659 and 9230 high-confidence DLAs that were previously unpublished). This work validates the application of deep learning techniques to astronomical spectra for both classification and quantitative measurements.}},
  author       = {Parks, David and Prochaska, J Xavier and Dong, Shawfeng and Cai, Zheng},
  url          = {https://doi.org/10.1093/mnras/sty196},
  date         = {2018-01},
  doi          = {10.1093/mnras/sty196},
  eprint       = {https://academic.oup.com/mnras/article-pdf/476/1/1151/24261051/sty196.pdf},
  issn         = {0035-8711},
  journaltitle = {Monthly Notices of the Royal Astronomical Society},
  number       = {1},
  pages        = {1151--1168},
  title        = {{Deep learning of quasar spectra to discover and characterize damped Ly$\alpha$ systems}},
  volume       = {476},
}

@inproceedings{vaswani2017,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  editor    = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  publisher = {Curran Associates, Inc.},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
  booktitle = {Advances in Neural Information Processing Systems},
  date      = {2017},
  title     = {Attention is All you Need},
  volume    = {30},
}

@article{dosovitskiy2020,
  author       = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  url          = {https://arxiv.org/abs/2010.11929},
  date         = {2020},
  eprint       = {2010.11929},
  eprinttype   = {arXiv},
  journaltitle = {CoRR},
  title        = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  volume       = {abs/2010.11929},
}

@article{popescu2009,
  author       = {Popescu, Marius-Constantin and Balas, Valentina and Perescu-Popescu, Liliana and Mastorakis, Nikos},
  date         = {2009-07},
  journaltitle = {WSEAS Transactions on Circuits and Systems},
  title        = {Multilayer perceptron and neural networks},
  volume       = {8},
}

@misc{neutelings2021_nn,
  author       = {Neutelings, Izaak},
  publisher    = {TikZ.net},
  url          = {https://tikz.net/neural_networks/},
  date         = {2021-09-26},
  journaltitle = {TikZ.net},
  title        = {Neural networks},
}

@misc{neutelings2022_conv,
  author       = {Neutelings, Izaak},
  publisher    = {TikZ.net},
  url          = {https://tikz.net/conv2d/},
  date         = {2022-04-09},
  journaltitle = {TikZ.net},
  title        = {Neural networks},
}

@article{Naskath2022,
  abstract     = {Deep learning is a wildly popular topic in machine learning and is structured as a series of nonlinear layers that learns various levels of data representations. Deep learning employs numerous layers to represent data abstractions to implement various computer models. Deep learning approaches like generative, discriminative models and model transfer have transformed information processing. This article proposes a comprehensive review of various deep learning algorithms Multi layer perception, Self-organizing map and deep belief networks algorithms. It first briefly introduces historical and recent state-of-the-art reviews with suitable architectures and implementation steps. Moreover, the various applications of those algorithms in various fields such as wireless networks, Adhoc networks, Mobile ad-hoc and vehicular ad-hoc networks, speech recognition engineering, medical applications, natural language processing, material science and remote sensing applications, etc. are classified.},
  author       = {Naskath, J. and Sivakamasundari, G. and Begum, A. Alif Siddiqua},
  url          = {https://doi.org/10.1007/s11277-022-10079-4},
  date         = {2022-10},
  doi          = {10.1007/s11277-022-10079-4},
  isbn         = {1572-834X},
  journaltitle = {Wireless Personal Communications},
  number       = {4},
  pages        = {2913--2936},
  title        = {A Study on Different Deep Learning Algorithms Used in Deep Neural Nets: MLP SOM and DBN},
  volume       = {128},
}

@misc{kumar2022_cnn,
  author       = {Kumar, Ajitesh},
  publisher    = {VitalFlux},
  url          = {https://vitalflux.com/different-types-of-cnn-architectures-explained-examples/},
  date         = {2022-04},
  journaltitle = {Data Analytics},
  title        = {Different types of CNN Architectures explained: Examples},
}

@misc{he2016deep,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/1512.03385},
  date      = {2015},
  doi       = {10.48550/ARXIV.1512.03385},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Computer and information sciences},
  title     = {Deep Residual Learning for Image Recognition},
}

@inproceedings{Simonyan15,
  author    = {Simonyan, Karen and Zisserman, Andrew},
  booktitle = {International Conference on Learning Representations},
  date      = {2015},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
}

@misc{Kim2014,
  author    = {Kim, Yoon},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/1408.5882},
  date      = {2014},
  doi       = {10.48550/ARXIV.1408.5882},
  keywords  = {Computation and Language (cs.CL),Neural and Evolutionary Computing (cs.NE),FOS: Computer and information sciences,FOS: Computer and information sciences},
  title     = {Convolutional Neural Networks for Sentence Classification},
}

@article{Kiranyaz2021,
  abstract     = {During the last decade, Convolutional Neural Networks (CNNs) have become the de facto standard for various Computer Vision and Machine Learning operations. CNNs are feed-forward Artificial Neural Networks (ANNs) with alternating convolutional and subsampling layers. Deep 2D CNNs with many hidden layers and millions of parameters have the ability to learn complex objects and patterns providing that they can be trained on a massive size visual database with ground-truth labels. With a proper training, this unique ability makes them the primary tool for various engineering applications for 2D signals such as images and video frames. Yet, this may not be a viable option in numerous applications over 1D signals especially when the training data is scarce or application specific. To address this issue, 1D CNNs have recently been proposed and immediately achieved the state-of-the-art performance levels in several applications such as personalized biomedical data classification and early diagnosis, structural health monitoring, anomaly detection and identification in power electronics and electrical motor fault detection. Another major advantage is that a real-time and low-cost hardware implementation is feasible due to the simple and compact configuration of 1D CNNs that perform only 1D convolutions (scalar multiplications and additions). This paper presents a comprehensive review of the general architecture and principals of 1D CNNs along with their major engineering applications, especially focused on the recent progress in this field. Their state-of-the-art performance is highlighted concluding with their unique properties. The benchmark datasets and the principal 1D CNN software used in those applications are also publicly shared in a dedicated website. While there has not been a paper on the review of 1D CNNs and its applications in the literature, this paper fulfills this gap.},
  author       = {Kiranyaz, Serkan and Avci, Onur and Abdeljaber, Osama and Ince, Turker and Gabbouj, Moncef and Inman, Daniel J.},
  url          = {https://www.sciencedirect.com/science/article/pii/S0888327020307846},
  date         = {2021},
  doi          = {https://doi.org/10.1016/j.ymssp.2020.107398},
  issn         = {0888-3270},
  journaltitle = {Mechanical Systems and Signal Processing},
  keywords     = {Artificial Neural Networks,Machine learning,Deep learning,Convolutional neural networks,Structural health monitoring,Condition monitoring,Arrhythmia detection and identification,Fault detection,Structural damage detection},
  pages        = {107398},
  title        = {1D convolutional neural networks and applications: A survey},
  volume       = {151},
}

@misc{Huang2016,
  author    = {Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q.},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/1608.06993},
  date      = {2016},
  doi       = {10.48550/ARXIV.1608.06993},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  title     = {Densely Connected Convolutional Networks},
}

@misc{Shelhamer2016,
  author    = {Shelhamer, Evan and Long, Jonathan and Darrell, Trevor},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/1605.06211},
  date      = {2016},
  doi       = {10.48550/ARXIV.1605.06211},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Computer and information sciences},
  title     = {Fully Convolutional Networks for Semantic Segmentation},
}

@thesis{rubenzahl2018,
  author      = {Rubenzahl, Ryan},
  institution = {University of Rochester},
  location    = {Rochester, NY},
  date        = {2018-05},
  title       = {Identifying Type Ia Supernovae in Extragalactic Spectra},
  type        = {Bachelor's Thesis},
}

@thesis{kitomi2019,
  author      = {Kitomi, Ouail},
  institution = {University of Rochester},
  location    = {Rochester, NY},
  date        = {2019-05},
  title       = {--},
  type        = {Bachelor's Thesis},
}

@thesis{Wasserman2020,
  author      = {Wasserman, Amanda},
  institution = {University of Rochester},
  location    = {Rochester, NY},
  date        = {2020-05},
  title       = {--},
  type        = {Bachelor's Thesis},
}

@thesis{Sepeku2022,
  author      = {Sepeku, Edmund},
  institution = {University of Rochester},
  location    = {Rochester, NY},
  date        = {2022-05},
  title       = {--},
  type        = {Bachelor's Thesis},
}

@article{Pence2010,
  author       = {{Pence, W. D.} and {Chiappetti, L.} and {Page, C. G.} and {Shaw, R. A.} and {Stobie, E.}},
  url          = {https://doi.org/10.1051/0004-6361/201015362},
  date         = {2010-11},
  doi          = {10.1051/0004-6361/201015362},
  journaltitle = {A\&A},
  pages        = {A42},
  title        = {Definition of the Flexible Image Transport System (FITS), version 3.0},
  volume       = {524},
}

@article{Guy2023,
  author       = {Guy, J. and Bailey, S. and Kremin, A. and Alam, Shadab and Alexander, D. M. and Prieto, C. Allende and BenZvi, S. and Bolton, A. S. and Brooks, D. and Chaussidon, E. and Cooper, A. P. and Dawson, K. and de la Macorra, A. and Dey, A. and Dey, Biprateep and Dhungana, G. and Eisenstein, D. J. and Font-Ribera, A. and Forero-Romero, J. E. and Gaztañaga, E. and Gontcho, S. Gontcho A and Green, D. and Honscheid, K. and Ishak, M. and Kehoe, R. and Kirkby, D. and Kisner, T. and Koposov, Sergey E. and Lan, Ting-Wen and Landriau, M. and Guillou, L. Le and Levi, Michael E. and Magneville, C. and Manser, Christopher J. and Martini, P. and Meisner, Aaron M. and Miquel, R. and Moustakas, J. and Myers, Adam D. and Newman, Jeffrey A. and Nie, Jundan and Palanque-Delabrouille, N. and Percival, W. J. and Poppett, C. and Prada, F. and Raichoor, A. and Ravoux, C. and Ross, A. J. and Schlafly, E. F. and Schlegel, D. and Schubnell, M. and Sharples, Ray M. and Tarlé, Gregory and Weaver, B. A. and Yéche, Christophe and Zhou, Rongpu and Zhou, Zhimin and Zou, H.},
  publisher    = {American Astronomical Society},
  url          = {https://doi.org/10.3847/1538-3881/acb212},
  date         = {2023-03},
  doi          = {10.3847/1538-3881/acb212},
  journaltitle = {The Astronomical Journal},
  number       = {4},
  pages        = {144},
  title        = {The Spectroscopic Data Processing Pipeline for the Dark Energy Spectroscopic Instrument},
  volume       = {165},
}

@article{Zwicky1938,
  author       = {{Zwicky}, F.},
  date         = {1938-12},
  doi          = {10.1086/144007},
  journaltitle = {\apj},
  pages        = {529},
  title        = {{On the Frequency of Supernovae.}},
  volume       = {88},
}

@inproceedings{Koenig2005,
  author    = {{Koenig}, T.},
  editor    = {{Turatto}, M. and {Benetti}, S. and {Zampieri}, L. and {Shea}, W.},
  booktitle = {1604-2004: Supernovae as Cosmological Lighthouses},
  date      = {2005-12},
  pages     = {53},
  series    = {Astronomical Society of the Pacific Conference Series},
  title     = {{Fritz Zwicky: Novae Become Supernovae}},
  volume    = {342},
}

@article{Schaefer1995,
  author       = {{Schaefer}, Bradley E.},
  date         = {1995-07},
  doi          = {10.1086/309549},
  journaltitle = {\apjl},
  keywords     = {COSMOLOGY: OBSERVATIONS,COSMOLOGY: DISTANCE SCALE,GALAXIES: INDIVIDUAL NGC NUMBER: NGC 5253,STARS: SUPERNOVAE: INDIVIDUAL ALPHANUMERIC: SN 1895B},
  pages        = {L13},
  title        = {{The Peak Brightness of SN 1895B in NGC 5253 and the Hubble Constant}},
  volume       = {447},
}

@article{deVaucouleurs1985,
  author       = {{de Vaucouleurs}, G. and {Corwin}, H. G., Jr.},
  date         = {1985-08},
  doi          = {10.1086/163374},
  journaltitle = {\apj},
  keywords     = {Andromeda Galaxy,Light Curve,Supernovae,Reference Stars,Stellar Color,Stellar Magnitude,Stellar Spectra,Supernova Remnants,Wavelengths,Astrophysics},
  pages        = {287},
  title        = {{S Andromedae 1885: A Centennial Review}},
  volume       = {295},
}

@article{Baade1934,
  author       = {Baade, W. and Zwicky, F.},
  publisher    = {National Academy of Sciences},
  url          = {http://www.jstor.org/stable/86841},
  date         = {1934},
  issn         = {00278424},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  number       = {5},
  pages        = {259--263},
  title        = {Cosmic Rays from Super-novae},
  urldate      = {2023-05-03},
  volume       = {20},
}

@article{Barbon1999,
  author       = {{Barbon}, R. and {Buondı́}, V. and {Cappellaro}, E. and {Turatto}, M.},
  date         = {1999-11},
  doi          = {10.1051/aas:1999404},
  eprint       = {astro-ph/9908046},
  eprintclass  = {astro-ph},
  eprinttype   = {arXiv},
  journaltitle = {\aaps},
  keywords     = {SUPERNOVAE AND SUPERNOVA REMNANTS: GENERAL,SURVEYS,GALAXIES: GENERAL,GALAXIES: STELLAR CONTENTS OF,Astrophysics},
  pages        = {531--536},
  title        = {{The Asiago Supernova Catalogue - 10 years after}},
  volume       = {139},
}

@article{Minkowski1941,
  author       = {{Minkowski}, R.},
  date         = {1941-08},
  doi          = {10.1086/125315},
  journaltitle = {\pasp},
  number       = {314},
  pages        = {224},
  title        = {{Spectra of Supernovae}},
  volume       = {53},
}

@incollection{Turatto2003,
  author    = {{Turatto}, M.},
  editor    = {{Weiler}, K.},
  booktitle = {Supernovae and Gamma-Ray Bursters},
  date      = {2003},
  doi       = {10.1007/3-540-45863-8_3},
  keywords  = {Astrophysics},
  pages     = {21--36},
  title     = {{Classification of Supernovae}},
  volume    = {598},
}

@article{Filippenko1997,
  author       = {{Filippenko}, Alexei V.},
  date         = {1997-01},
  doi          = {10.1146/annurev.astro.35.1.309},
  journaltitle = {\araa},
  pages        = {309--355},
  title        = {{Optical Spectra of Supernovae}},
  volume       = {35},
}

@article{Perlmutter1999,
  author       = {{Perlmutter}, S. and {Pennypacker}, C. R. and {Goldhaber}, G. and {Goobar}, A. and {Muller}, R. A. and {Newberg}, H. J. M. and {Desai}, J. and {Kim}, A. G. and {Kim}, M. Y. and {Small}, I. A. and {Boyle}, B. J. and {Crawford}, C. S. and {McMahon}, R. G. and {Bunclark}, P. S. and {Carter}, D. and {Irwin}, M. J. and {Terlevich}, R. J. and {Ellis}, R. S. and {Glazebrook}, K. and {Couch}, W. J. and {Mould}, J. R. and {Small}, T. A. and {Abraham}, R. G.},
  date         = {1995-02},
  doi          = {10.1086/187756},
  eprint       = {astro-ph/9505023},
  eprintclass  = {astro-ph},
  eprinttype   = {arXiv},
  journaltitle = {\apjl},
  keywords     = {Cosmology,Deceleration,Error Analysis,Red Shift,Supernovae,Charge Coupled Devices,Dark Matter,Light Curve,Stellar Spectrophotometry,Astrophysics,Astrophysics},
  pages        = {L41},
  title        = {{A Supernova at Z = 0.458 and Implications for Measuring the Cosmological Deceleration}},
  volume       = {440},
}

@article{Mikolov2013,
  author       = {{Mikolov}, Tomas and {Chen}, Kai and {Corrado}, Greg and {Dean}, Jeffrey},
  date         = {2013-01},
  doi          = {10.48550/arXiv.1301.3781},
  eid          = {arXiv:1301.3781},
  eprint       = {1301.3781},
  eprintclass  = {cs.CL},
  eprinttype   = {arXiv},
  journaltitle = {arXiv e-prints},
  keywords     = {Computer Science - Computation and Language},
  pages        = {arXiv:1301.3781},
  title        = {{Efficient Estimation of Word Representations in Vector Space}},
}

@article{Nassif2019,
  author       = {Nassif, Ali Bou and Shahin, Ismail and Attili, Imtinan and Azzeh, Mohammad and Shaalan, Khaled},
  date         = {2019},
  doi          = {10.1109/ACCESS.2019.2896880},
  journaltitle = {IEEE Access},
  pages        = {19143--19165},
  title        = {Speech Recognition Using Deep Neural Networks: A Systematic Review},
  volume       = {7},
}

@article{Becker2021,
  author       = {{Becker}, Burger and {Vaccari}, Mattia and {Prescott}, Matthew and {Grobler}, Trienko},
  date         = {2021-05},
  doi          = {10.1093/mnras/stab325},
  eprint       = {2102.03780},
  eprintclass  = {astro-ph.GA},
  eprinttype   = {arXiv},
  journaltitle = {\mnras},
  keywords     = {methods: statistical,techniques: image processing,surveys,radio continuum: galaxies,Astrophysics - Astrophysics of Galaxies},
  number       = {2},
  pages        = {1828--1846},
  title        = {{CNN architecture comparison for radio galaxy classification}},
  volume       = {503},
}

@article{Gauci2010,
  author       = {{Gauci}, Adam and {Zarb Adami}, Kristian and {Abela}, John},
  date         = {2010-05},
  doi          = {10.48550/arXiv.1005.0390},
  eid          = {arXiv:1005.0390},
  eprint       = {1005.0390},
  eprintclass  = {astro-ph.GA},
  eprinttype   = {arXiv},
  journaltitle = {arXiv e-prints},
  keywords     = {Astrophysics - Galaxy Astrophysics,Computer Science - Machine Learning},
  pages        = {arXiv:1005.0390},
  title        = {{Machine Learning for Galaxy Morphology Classification}},
}

@article{Mller2016,
  author       = {Möller, A. and Ruhlmann-Kleider, V. and Leloup, C. and Neveu, J. and Palanque-Delabrouille, N. and Rich, J. and Carlberg, R. and Lidman, C. and Pritchet, C.},
  publisher    = {{IOP} Publishing},
  url          = {https://doi.org/10.1088/1475-7516/2016/12/008},
  date         = {2016-12},
  doi          = {10.1088/1475-7516/2016/12/008},
  journaltitle = {Journal of Cosmology and Astroparticle Physics},
  number       = {12},
  pages        = {008--008},
  title        = {Photometric classification of type Ia supernovae in the {SuperNova} Legacy Survey with supervised learning},
  volume       = {2016},
}

